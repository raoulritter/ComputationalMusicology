---
title: "Raoul Ritter"
date: "25/3/2022"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: 
      version: 4
      bootswatch: minty
---
```{r setup}
library(tidyverse)
library(tidymodels)
library(plotly)
library(protoclust)
library(spotifyr)
library(compmus)
library(flexdashboard)
library(tidyverse)
library(ggdendro)
library(kknn)
TLOP <- get_playlist_audio_features("","6xMmY2bJcoRfTYnbaswB81")
DONDA <- get_playlist_audio_features("","6CBjIOCvkEnNom6zr2CzZt")
YE <- get_playlist_audio_features("","3ttuqnv3RBZ2tT6Fommpyf")
JIK <- get_playlist_audio_features("","3Zea55ELBEcnURbXY1uH3P")
MBDTF <- get_playlist_audio_features("","38LsK6yyXI0apx7n7bbx8i")
YEEZUS <- get_playlist_audio_features("","753uZalNXz3Lv6FreyTWiF")
HEARTBREAKS <- get_playlist_audio_features("","3nH7CBa7ohrAU9k2t7aMgM")
ALL <- rbind(TLOP,DONDA,JIK,MBDTF,YEEZUS,HEARTBREAKS,YE)
```
### Introduction

For my corpus I will be looking at the 7 (solo) studio albums by Kanye West that he created after the death of his mother. Online there is often a theory that these albums correspond with the stages of grief. During this assignment I would like to check if these albums indeed follow this pattern.

1. Shock (808â€™s and Heartbreak)
2. Denial (My Beautiful Dark Twisted Fantasy)
3. Anger (Yeezus)
4. Bargaining (The Life of Pablo or TLOP)
5. Depression (Ye)
6. Testing (JESUS IS KING)
7. Acceptance (DONDA)
I would like to do this analysis by taking a look at the information that the spotify API provides such as valence, tempo and speechiness in order to analyse if these albums indeed could be catagorized as having differentes that could be recognized as corresponding to the stages of grief.

I think the corpus has a large variety as the albums while listening give off a very different feeling.

Some songs that stand out in this corpus are Power from the album Denial which comes from the album My Beautiful Dark Twisted Fantasy. Which comes off as quite a angry song aswell. Issues could also stem from the fact that Ye has conststently made changes to his albums. One example of this is for TLOP in which he changed multiple segments in songs aswell as completely adding a new song Saint Pablo to the album. However the issue is that spotify only has the most recent version of his album. Therefore it is difficult to recognize if the changes he has made on a single album also reflect the changes in his process. But.

### Global Overview of All Albums

```{r fig.height = 10, fig.width = 12}
ALL %>% 
ggplot(aes(x = valence, y = energy, color = playlist_name)) +
  geom_jitter() +
  geom_vline(xintercept = 0.5) +
  geom_hline(yintercept = 0.5) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1)) +
  annotate('text', 0.25 / 2, 0.95, label = "Turbulent/Angry", fontface = "bold") +
  annotate('text', 1.75 / 2, 0.95, label = "Happy/Joyful", fontface = "bold") +
  annotate('text', 1.75 / 2, 0.05, label = "Chill/Peaceful", fontface = "bold") +
  annotate('text', 0.25 / 2, 0.05, label = "Sad/Depressing", fontface = "bold")

```

### Section 2 

Section 2




### Section 3

Section 3




### Section 4

Section 4


### Section 5

Section 5


### Section 6

Section 6

### Section 7

Section 7

### Section 12

```{r classification}

TLOP <- get_playlist_audio_features("","6xMmY2bJcoRfTYnbaswB81")
DONDA <- get_playlist_audio_features("","6CBjIOCvkEnNom6zr2CzZt")
YE <- get_playlist_audio_features("","3ttuqnv3RBZ2tT6Fommpyf")

pop <- 
    get_playlist_audio_features('spotify', '6xMmY2bJcoRfTYnbaswB81') %>% 
    add_audio_analysis
party <- 
    get_playlist_audio_features('spotify', '6CBjIOCvkEnNom6zr2CzZt') %>% 
    add_audio_analysis
workout <- 
    get_playlist_audio_features('spotify', '3ttuqnv3RBZ2tT6Fommpyf') %>% 
    add_audio_analysis
indie <- 
    pop %>% mutate(playlist = "TLOP") %>% 
    bind_rows(
        party %>% mutate(playlist = "Donda"),
        workout %>% mutate(playlist = "Ye")) %>% 
    mutate(playlist = factor(playlist)) %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre), map, bind_rows) %>% 
    unnest(cols = c(pitches, timbre))
indie_juice <- 
    recipe(playlist ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = indie) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>% 
    prep(indie) %>% 
    juice
indie_cv <- indie_juice %>% vfold_cv(10)
indie_knn <- 
  nearest_neighbor(mode = 'classification', neighbors = 1) %>% 
  set_engine('kknn')
predict_knn_reduced <- function(split) {
    fit(
        indie_knn, 
        playlist ~ c01 + liveness + acousticness + c02 + energy, 
        data = analysis(split)) %>% 
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
}
indie_cv %>% 
    mutate(pred = map(splits, predict_knn_reduced)) %>% unnest(pred) %>% 
    conf_mat(truth = playlist, estimate = .pred_class) %>% 
    autoplot(type = 'mosaic')
```

