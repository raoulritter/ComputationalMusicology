---
title: "Portfolio Computational Musicology 2022 Kanye West's Albums and the stages of grief"
date: "Raoul Ritter"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    theme: 
      version: 4
      bootswatch: minty
---
```{r setup}
library(tidyverse)
library(tidymodels)
library(plotly)
library(protoclust)
library(spotifyr)
library(compmus)
library(flexdashboard)
library(tidyverse)
library(ggdendro)
library(kknn)
TLOP <- get_playlist_audio_features("","6xMmY2bJcoRfTYnbaswB81")
DONDA <- get_playlist_audio_features("","6CBjIOCvkEnNom6zr2CzZt")
YE <- get_playlist_audio_features("","3ttuqnv3RBZ2tT6Fommpyf")
JIK <- get_playlist_audio_features("","3Zea55ELBEcnURbXY1uH3P")
MBDTF <- get_playlist_audio_features("","38LsK6yyXI0apx7n7bbx8i")
YEEZUS <- get_playlist_audio_features("","753uZalNXz3Lv6FreyTWiF")
HEARTBREAKS <- get_playlist_audio_features("","3nH7CBa7ohrAU9k2t7aMgM")
ALL <- rbind(TLOP,DONDA,JIK,MBDTF,YEEZUS,HEARTBREAKS,YE)
```
### Introduction

For my corpus I will be looking at the 7 (solo) studio albums by Kanye West that he created after the death of his mother. Online there is often a theory that these albums correspond with the stages of grief. During this assignment I would like to check if these albums indeed follow this pattern.

1. Shock (808â€™s and Heartbreak)
2. Denial (My Beautiful Dark Twisted Fantasy)
3. Anger (Yeezus)
4. Bargaining (The Life of Pablo or TLOP)
5. Depression (Ye)
6. Testing (JESUS IS KING)
7. Acceptance (DONDA)

In this project I will be analyzing these albums using the information that the spotify API provides such as valence, tempo and speechiness. These variables will be used to analyse if these albums can be categorized as having unique features that correspond to the stages of grief.

The corpus consists of exactly 100 songs. Which knowing Ye is not an accident. The corpus has a large variety of songs and feelings across the different albums. The difficulty in this corpus is if the albums are truly unique or if the diversity of features in songs per album are too large to distinguish.  

Some songs that stand out in this corpus are Power from the album Denial which comes from the album My Beautiful Dark Twisted Fantasy. Which comes off as quite a angry song as well. Issues could also stem from the fact that Ye has consistently made changes to his albums. One example of this is for TLOP in which he changed multiple segments in songs as well as completely adding a new song Saint Pablo to the album. However the issue is that spotify only has the most recent version of his album. Therefore it is difficult to recognize if the changes he has made on a single album also reflect the changes in his process.

### Global Overview of All Albums

```{r fig.height = 10, fig.width = 12}
ALL %>% 
ggplot(aes(x = valence, y = energy, color = playlist_name)) +
  geom_jitter() +
  geom_vline(xintercept = 0.5) +
  geom_hline(yintercept = 0.5) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1)) +
  annotate('text', 0.25 / 2, 0.95, label = "Turbulent/Angry", fontface = "bold") +
  annotate('text', 1.75 / 2, 0.95, label = "Happy/Joyful", fontface = "bold") +
  annotate('text', 1.75 / 2, 0.05, label = "Chill/Peaceful", fontface = "bold") +
  annotate('text', 0.25 / 2, 0.05, label = "Sad/Depressing", fontface = "bold")

```

***

This graph gives a global analysis of the overall atmosphere of the music of the 7 Studio Albums that Kanye West released after his mothers death. 

According to the Spotify API, **Energy** is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy.

**Valence** is a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

The interesting thing we see at first glance is that there is quite an even distribution between the different albums. They are not specifically as select into their specific segments as we might have thought. However on closer inspection you can see that there are clear differences between certain albums. For example Yeezus which we would associate with anger has most of it's song in the Turbulent/Angry section. Similar case for MBDTF. However Donda has a very diverse spectrum being in three different segments and not having real clustering. However it could also be that due to the style of Kanye West's music largely being Hip Hop these songs are often seen as being in the Angry due to being higher in energy and lower in valance resulting in this clustering. 

<iframe src="https://open.spotify.com/embed/playlist/2benrUkgKv28fkKoBowcFU?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

### Analysis of Given methods

Section 2


```{r}
FG <-
  get_tidy_audio_analysis("2QpGZOhTCHHiKmpSO9FW4h") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
FG %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") + ggtitle("Follow God from JIK by Kanye West")
hurricane <-
  get_tidy_audio_analysis("6Hfu9sc7jvv6coyy2LlzBF") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
hurricane %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") + ggtitle("Hurricane from the Donda album by Kanye West")
```



### Section 3

Section 3

```{r}
ALL <-
  TLOP %>%
  mutate(country = "TLOP") %>%
  bind_rows(DONDA %>% mutate(country = "DONDA")) %>%
  bind_rows(YE %>% mutate(country = "Ye")) %>%
  bind_rows(JIK %>% mutate(country = "Jesus is King")) %>%
  bind_rows(MBDTF %>% mutate(country = "My beautiful dark twisted fantasy")) %>%
  bind_rows(YEEZUS %>% mutate(country = "Yeezus")) %>%
  bind_rows(HEARTBREAKS %>% mutate(country = "808's and Heartbreaks")) %>%
  mutate(
    country = fct_relevel(country, "TLOP", "Donda", "Ye", "Jesus is King", "My beautiful dark twisted fantasy", "Yeezus","808's and Heartbreaks")
  )

february_dip <-
  ALL %>%
  ggplot(                          # Set up the plot.
    aes(
      x = valence,
      y = energy,
      size = track.popularity,
      colour = danceability,
      label = track.name           # Labels will be interactively visible.
    )
  ) +
  geom_point() +                   # Scatter plot.
  geom_rug(size = 0.1) +           # Add 'fringes' to show data distribution.
  facet_wrap(~country) +           # Separate charts per country.
  scale_x_continuous(              # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),        # Use grid-lines for quadrants only.
    minor_breaks = NULL            # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(              # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_viridis_c(          # Use the cividis palette
    option = "E",                  # Qualitative set.
    alpha = 0.8,                   # Include some transparency
    guide = "none"
  ) +
  scale_size_continuous(           # Fine-tune the sizes of each point.
    guide = "none"                 # Remove the legend for size.
  ) +
  theme_dark() +                  # Use a simpler theme.
  labs(                            # Make the titles nice.
    x = "Valence",
    y = "Energy"
  )

ggplotly(february_dip)

```
### Section 4

Section 4


### Section 5

Section 5


### Section 6

Section 6

### Section 7

Section 7

### Section 12

```{r classification}

TLOP <- get_playlist_audio_features("","6xMmY2bJcoRfTYnbaswB81")
DONDA <- get_playlist_audio_features("","6CBjIOCvkEnNom6zr2CzZt")
YE <- get_playlist_audio_features("","3ttuqnv3RBZ2tT6Fommpyf")

pop <- 
    get_playlist_audio_features('spotify', '6xMmY2bJcoRfTYnbaswB81') %>% 
    add_audio_analysis
party <- 
    get_playlist_audio_features('spotify', '6CBjIOCvkEnNom6zr2CzZt') %>% 
    add_audio_analysis
workout <- 
    get_playlist_audio_features('spotify', '3ttuqnv3RBZ2tT6Fommpyf') %>% 
    add_audio_analysis
indie <- 
    pop %>% mutate(playlist = "TLOP") %>% 
    bind_rows(
        party %>% mutate(playlist = "Donda"),
        workout %>% mutate(playlist = "Ye")) %>% 
    mutate(playlist = factor(playlist)) %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre), map, bind_rows) %>% 
    unnest(cols = c(pitches, timbre))
indie_juice <- 
    recipe(playlist ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = indie) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>% 
    prep(indie) %>% 
    juice
indie_cv <- indie_juice %>% vfold_cv(10)
indie_knn <- 
  nearest_neighbor(mode = 'classification', neighbors = 1) %>% 
  set_engine('kknn')
predict_knn_reduced <- function(split) {
    fit(
        indie_knn, 
        playlist ~ c01 + liveness + acousticness + c02 + energy, 
        data = analysis(split)) %>% 
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
}
indie_cv %>% 
    mutate(pred = map(splits, predict_knn_reduced)) %>% unnest(pred) %>% 
    conf_mat(truth = playlist, estimate = .pred_class) %>% 
    autoplot(type = 'mosaic')
```

